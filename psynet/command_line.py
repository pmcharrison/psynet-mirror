import errno, json
import os
import shutil

import click
import requests
from yaspin import yaspin

from dallinger import data as dallinger_data
from dallinger.command_line import verify_id, log
# from dallinger.config import get_config
from dallinger.models import (
    Info,
    Network,
    Node,
    Notification,
    Participant,
    Question,
    Transformation,
    Transmission,
    Vector,
)
from dallinger.utils import get_base_url

from psynet import __version__
from .utils import (
    import_local_experiment,
    json_to_data_frame,
    model_name_to_snake_case,
    serialise,
)

FLAGS = set()

header = r"""
    ____             _   __     __
   / __ \_______  __/ | / /__  / /_
  / /_/ / ___/ / / /  |/ / _ \/ __/
 / ____(__  ) /_/ / /|  /  __/ /_
/_/   /____/\__, /_/ |_/\___/\__/
           /____/
                                 {:>8}

                Laboratory automation for
       the behavioral and social sciences.
""".format(
    "v" + __version__
)

@click.group()
@click.version_option(__version__, "--version", "-v", message="%(version)s")
def psynet():
    pass
    # 1 + 1
    # config = get_config()
    # if not config.ready:
    #     import pdb; pdb.set_trace()
    #     config.load()

@psynet.command()
@click.option("--verbose", is_flag=True, flag_value=True, help="Verbose mode.")
@click.option("--force", is_flag=True, flag_value=True, help="Force override of cache.")
def prepare(verbose, force):
    """
    Prepares all stimulus sets defined in experiment.py,
    uploading all media files to Amazon S3.
    """
    FLAGS.add("prepare")
    if force:
        FLAGS.add("force")
    import_local_experiment()

@psynet.command()
@click.option("--app", default=None, callback=verify_id, help="Experiment app name")
@click.option("--local", is_flag=True, flag_value=True, help="Export local data")
def export(app, local):
    """
        Export data from an experiment.

        The data is exported in three distinct formats into the 'data' directory
        of an experiment which has following structure:

        data/
        ├── csv/
        ├── db-snapshot/
        └── json/

        csv:
            Contains the experiment data in CSV format.
        db-snapshot:
            Contains the zip file generated by the default Dallinger export command.
        json:
            Contains the experiment data in JSON format.
    """
    log(header, chevrons=False)
    import_local_experiment()
    create_export_dirs()

    log("Creating database snapshot.")
    dallinger_data.export(app, local=local)
    move_snapshot_file(app)
    with yaspin(text="Completed.", color="green") as spinner:
        spinner.ok("✔")

    log("Exporting 'json' and 'csv' files.")
    dallinger_models = [
        Info,
        Network,
        Node,
        Notification,
        Participant,
        Question,
        Transformation,
        Transmission,
        Vector,
    ]

    base_url = get_base_url() if local else f"https://dlgr-{app}.herokuapp.com"

    for dallinger_model in dallinger_models:
        class_name = dallinger_model.__name__
        result = requests.get(f"{base_url}/export",
                              params={"class_name": class_name})
        json_data = json.loads(result.content.decode('utf8'))

        for model_name, json_data in json_data.items():
            base_filename = model_name_to_snake_case(model_name)
            print(f"Exporting {base_filename} data...")
            with yaspin(text="Exporting 'json'...", color="green") as spinner:
                base_filepath = os.path.join("data", "json", base_filename)
                with open(f"{base_filepath}.json", "w") as outfile:
                    json.dump(json_data, outfile, indent=2, sort_keys=False, default=serialise)
                spinner.ok("✔")
            with yaspin(text="Exporting 'csv'...", color="green") as spinner:
                base_filepath = os.path.join("data", "csv", base_filename)
                with open(f"{base_filepath}.csv", "w") as outfile:
                    data_frame = json_to_data_frame(json_data)
                    data_frame.to_csv(outfile, index=False)
                spinner.ok("✔")
    log("Export completed.")

def create_export_dirs():
    for file_format in ["csv", "db-snapshot", "json"]:
        export_path = os.path.join("data", file_format)
        try:
            os.makedirs(export_path)
        except OSError as e:
            if e.errno != errno.EEXIST or not os.path.isdir(export_path):
                raise

def move_snapshot_file(app):
    try:
        db_snapshot_path = os.path.join("data", "db-snapshot")
        filename = f"{app}-data.zip"
        shutil.move(
            os.path.join("data", filename),
            os.path.join(db_snapshot_path, filename)
        )
    except OSError as e:
        if e.errno != errno.EEXIST or not os.path.isdir(db_snapshot_path):
            raise
