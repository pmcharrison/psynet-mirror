import dallinger.models
import sqlalchemy
from dallinger import db
from dallinger.db import Base as SQLBase  # noqa
from dallinger.db import init_db  # noqa
from dallinger.experiment_server import dashboard
from dallinger.models import Info  # noqa
from dallinger.models import Network  # noqa
from dallinger.models import Node  # noqa
from dallinger.models import Notification  # noqa
from dallinger.models import Question  # noqa
from dallinger.models import Transformation  # noqa
from dallinger.models import Transmission  # noqa
from dallinger.models import Vector  # noqa
from dallinger.models import SharedMixin, timenow  # noqa
from progress.bar import Bar
from sqlalchemy import Column, String
from sqlalchemy.ext.declarative import declared_attr
from sqlalchemy.schema import (
    DropConstraint,
    DropTable,
    ForeignKeyConstraint,
    MetaData,
    Table,
)

from . import field
from .field import VarStore
from .utils import classproperty


def export(class_name):
    """
    Export data from an experiment.

    Collects instance data for class_name, including inheriting models.
    """
    models = {}
    instances = db_models()[class_name].query.all()
    if len(instances) == 0:
        return models
    with Bar(f"Serializing {class_name} instances", max=len(instances)) as bar:
        for instance in instances:
            model = instance.__class__.__name__
            if model not in models:
                models[model] = []
            models[model].append(instance.__json__())
            bar.next()
    return models


class SQLMixinDallinger(SharedMixin):
    """
    We apply this Mixin class when subclassing Dallinger classes,
    for example ``Network`` and ``Info``.
    It adds a few useful exporting features,
    but most importantly it adds automatic mapping logic,
    so that polymorphic identities are constructed automatically from
    class names instead of having to be specified manually.
    For example:

    ```py
    from dallinger.models import Info

    class CustomInfo(Info)
        pass
    ```
    """

    __extra_vars__ = {}

    @property
    def var(self):
        return VarStore(self)

    def __json__(self):
        """
        Determines the information that is shown for this object in the dashboard
        and in the csv files generated by ``psynet export``.
        """
        x = {c: getattr(self, c) for c in self.sql_columns}

        field.json_clean(x, details=True)
        field.json_add_extra_vars(x, self)
        field.json_format_vars(x)

        return x

    @classproperty
    def sql_columns(cls):
        return cls.__mapper__.column_attrs.keys()

    @classproperty
    def inherits_table(cls):
        for ancestor_cls in cls.__mro__[1:]:
            if (
                hasattr(ancestor_cls, "__tablename__")
                and ancestor_cls.__tablename__ is not None
            ):
                return True
        return False

    @declared_attr
    def __mapper_args__(cls):
        """
        This programmatic definition of polymorphic_identity and polymorphic_on
        means that users can define new SQLAlchemy classes without any reference
        to these SQLAlchemy constructs. Instead the polymorphic mappers are
        constructed automatically based on class names.
        """
        x = {"polymorphic_identity": cls.__name__}
        if not cls.inherits_table:
            x["polymorphic_on"] = cls.type
        return x


class SQLMixin(SQLMixinDallinger):
    """
    We apply this mixin when creating our own SQL-backed
    classes from scratch. For example:

    ```
    from psynet.data import SQLBase, SQLMixin, register_table

    @register_table
    class Bird(SQLBase, SQLMixin):
        __tablename__ = "bird"

    class Sparrow(Bird):
        pass
    ```
    """

    @declared_attr
    def type(cls):
        return Column(String(50))


def drop_all_db_tables(bind=db.engine):
    """
    Drops all tables from the Postgres database.
    Includes a workaround for the fact that SQLAlchemy doesn't provide a CASCADE option to ``drop_all``,
    which was causing errors with Dallinger's version of database resetting in ``init_db``.

    (https://github.com/pallets-eco/flask-sqlalchemy/issues/722)
    """
    engine = bind

    con = engine.connect()
    trans = con.begin()
    inspector = sqlalchemy.inspect(engine)

    # We need to re-create a minimal metadata with only the required things to
    # successfully emit drop constraints and tables commands for postgres (based
    # on the actual schema of the running instance)
    meta = MetaData()
    tables = []
    all_fkeys = []

    for table_name in inspector.get_table_names():
        fkeys = []

        for fkey in inspector.get_foreign_keys(table_name):
            if not fkey["name"]:
                continue

            fkeys.append(ForeignKeyConstraint((), (), name=fkey["name"]))

        tables.append(Table(table_name, meta, *fkeys))
        all_fkeys.extend(fkeys)

    for fkey in all_fkeys:
        con.execute(DropConstraint(fkey))

    for table in tables:
        con.execute(DropTable(table))

    trans.commit()


dallinger.db.Base.metadata.drop_all = drop_all_db_tables


def dallinger_models():
    "A list of all base models in Dallinger"
    from .participant import Participant

    return {
        "Info": Info,
        "Network": Network,
        "Node": Node,
        "Notification": Notification,
        "Participant": Participant,
        "Question": Question,
        "Transformation": Transformation,
        "Transmission": Transmission,
        "Vector": Vector,
    }


# Extra base models that are defined in PsyNet or in the experiment itself
extra_models = {}


def db_models():
    "Together, this list of models should cover all the base classes in the database."
    return {
        **dallinger_models(),
        **extra_models,
    }


def register_table(cls):
    """
    This decorator should be applied whenever defining a new
    SQLAlchemy table.
    For example:

    ``` py
    @register_table
    class Bird(SQLBase, SQLMixin):
        __tablename__ = "bird"
    ```
    """
    extra_models[cls.__name__] = cls
    setattr(dallinger.models, cls.__name__, cls)
    update_dashboard_models()
    return cls


def update_dashboard_models():
    "Determines the list of objects in the dashboard database browser."
    from .timeline import Response
    from .trial.main import Trial

    dallinger.models.Trial = Trial
    dallinger.models.Response = Response

    dashboard.BROWSEABLE_MODELS = [
        "Participant",
        "Network",
        "Node",
        "Trial",
        "Response",
        "Transformation",
        "Transmission",
        "Notification",
    ] + list(extra_models)
